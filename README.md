# ğŸ“„ DocQA â€“ Retrievalâ€‘Augmented Document Question Answering

**Author:** Siddhesh Pitale

**GitHub:** [https://github.com/Siddheshpitale](https://github.com/Siddheshpitale)

**Repository:** [https://github.com/Siddheshpitale/DocQA-](https://github.com/Siddheshpitale/DocQA-)

---

## ğŸš€ Overview

**DocQA** is a Djangoâ€‘based Document Question Answering system powered by a **Retrievalâ€‘Augmented Generation (RAG)** pipeline. It allows users to upload PDF documents and ask naturalâ€‘language questions, returning **accurate, contextâ€‘aware answers with exact pageâ€‘level citations**.

This project is designed to be **modular, explainable, and hackathonâ€‘ready**, with a clean separation between UI, backend orchestration, and the intelligence pipeline.

---

## âœ¨ Key Features

* ğŸ“¤ Upload any PDF document
* ğŸ’¬ Ask questions in natural language
* ğŸ§  RAGâ€‘based answers grounded in document context
* ğŸ“Œ Pageâ€‘level source attribution
* ğŸŒ— Clean UI with Dark/Light mode
* âš¡ Modular pipeline (easy to extend or swap components)

---

## ğŸ—ï¸ System Architecture

```
DocQA/
â”œâ”€â”€ config/        # Django project configuration
â”œâ”€â”€ frontend/     # UI, views, and request handling
â”œâ”€â”€ rag/          # Core RAG intelligence pipeline
â”œâ”€â”€ manage.py
â”œâ”€â”€ db.sqlite3
â””â”€â”€ .env
```

### ğŸ”¹ Frontend Layer (`frontend/`)

* Handles PDF upload and user queries
* Renders answers and citations
* Communicates with the RAG pipeline via Django views

### ğŸ”¹ RAG Pipeline (`rag/`)

* **loader.py** â€“ PDF ingestion and text extraction
* **chunker.py** â€“ Splits text into semantic chunks
* **embedder.py** â€“ Converts text into embeddings
* **vectorstore.py / store.py** â€“ Stores and manages vectors
* **retriever.py** â€“ Semantic search over documents
* **qa.py** â€“ Contextâ€‘aware answer generation
* **pipeline.py** â€“ Orchestrates the full RAG workflow

---

## ğŸ§  How It Works

1. User uploads a PDF
2. Text is extracted and chunked
3. Chunks are embedded and stored in a vector database
4. User asks a question
5. Relevant chunks are retrieved via semantic search
6. An answer is generated using retrieved context
7. Source pages are displayed for transparency

---

## ğŸ› ï¸ Tech Stack

* **Backend:** Django (Python)
* **AI Pipeline:** Retrievalâ€‘Augmented Generation (RAG)
* **Embeddings:** Configurable (API/local models)
* **Vector Store:** Local / pluggable
* **Frontend:** HTML, CSS, JavaScript

---

## âš™ï¸ Setup & Installation

```bash
# Clone the repository
git clone https://github.com/Siddheshpitale/DocQA-
cd DocQA-

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Add environment variables
# Create a .env file and add required API keys

# Run migrations
python manage.py migrate

# Start server
python manage.py runserver
```

Open: **[http://127.0.0.1:8000/](http://127.0.0.1:8000/)**

---

## ğŸ¯ Use Cases

* Academic document understanding
* Research paper Q&A
* Legal or policy document analysis
* Internal company documentation search

---

## ğŸ† Why DocQA?

* Explainable AI with citations
* Clean, scalable architecture
* Productionâ€‘minded design
* Perfect for demos, hackathons, and extensions

---

## ğŸ“Œ Future Enhancements

* Multiple document support
* Confidence scoring
* Answer summarization modes
* Vector DB swap (FAISS / Chroma)
* Deployment with Docker

---

## ğŸ“œ License

This project is openâ€‘source and available under the **MIT License**.

---

â­ If you find this project useful, consider giving it a star on GitHub!
